#!/usr/bin/env python3
"""
Translation Notes AI - Main Application (Refactored)
Orchestrates the translation notes AI system with improved modularity and security.
"""

import os
import sys
import signal
import logging
import traceback
import atexit
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import threading
import time

# Add the project root to the Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# Import our well-organized modules
from modules import (
    ConfigManager, setup_logging, SheetManager, AIService, CacheManager,
    BatchProcessor, ContinuousBatchManager, ErrorNotifier,
    SecurityValidator, ConfigSecurityValidator,
    NotificationSystem, post_process_text,
    TranslationNotesAICLI, main_cli_entry_point,
    ItemProcessor
)


class TranslationNotesAI:
    """Main application class that orchestrates the translation notes AI system.
    
    This refactored version is much cleaner and uses proper separation of concerns.
    """
    
    def __init__(self):
        """Initialize the application with proper error handling and security validation."""
        # Initialize core configuration and logging
        self.config = ConfigManager()
        self.logger = setup_logging(self.config)
        
        # Set up exit debugging
        self._setup_exit_debugging()
        
        # Get timing configuration
        self.timing_config = self.config.get_timing_config()
        
        # Initialize security components
        self.security_validator = SecurityValidator(self.logger)
        self.config_security = ConfigSecurityValidator(self.logger)
        
        # Validate configuration security
        self._validate_configuration_security()
        
        # Initialize application state
        self.running = False
        self.last_error_notification = None
        self.error_count = 0
        self.use_continuous_processing = self.config.get('processing.use_continuous_batch_processing', True)
        self.immediate_mode_enabled = False
        
        # Initialize notification system
        self.notification_system = NotificationSystem(
            logger=self.logger,
            enabled=False  # Will be enabled via command line if requested
        )
        
        # Permission error tracking for legacy mode
        self.blocked_sheets: Dict[str, datetime] = {}
        self.permission_block_hours = self.config.get('processing.permission_block_hours', 1)
        
        # Initialize core components
        self._initialize_components()
        
        self.logger.info("Translation Notes AI initialized successfully")
        self.logger.info(f"Continuous processing: {'ENABLED' if self.use_continuous_processing else 'DISABLED'}")
        self.logger.info(f"Immediate mode: {'DISABLED (will be enabled if --immediate-mode flag is used)' if not self.immediate_mode_enabled else 'ENABLED'}")
        self.logger.info(f"Process ID: {os.getpid()}")
        self.logger.info(f"Python version: {sys.version}")
        self.logger.info(f"Working directory: {os.getcwd()}")
        self.logger.info("Keyboard shortcuts: Ctrl+C (soft stop) -> Ctrl+C (graceful stop) -> Ctrl+C (force exit)")
    
    def _setup_exit_debugging(self):
        """Set up comprehensive exit and error debugging."""
        # Register exit handler
        atexit.register(self._on_exit)
        
        # Set up exception hook for unhandled exceptions
        original_excepthook = sys.excepthook
        def exception_handler(exc_type, exc_value, exc_traceback):
            if exc_type is KeyboardInterrupt:
                self.logger.info("KeyboardInterrupt received, shutting down...")
            else:
                self.logger.error(f"Unhandled exception: {exc_type.__name__}: {exc_value}")
                self.logger.error("Traceback:")
                for line in traceback.format_tb(exc_traceback):
                    self.logger.error(line.rstrip())
            original_excepthook(exc_type, exc_value, exc_traceback)
        
        sys.excepthook = exception_handler
        
        # Set up thread exception handler for Python 3.8+
        if hasattr(threading, 'excepthook'):
            def thread_exception_handler(args):
                self.logger.error(f"Unhandled exception in thread {args.thread.name}: {args.exc_type.__name__}: {args.exc_value}")
                if args.exc_traceback:
                    self.logger.error("Thread traceback:")
                    for line in traceback.format_tb(args.exc_traceback):
                        self.logger.error(line.rstrip())
            
            threading.excepthook = thread_exception_handler
    
    def _on_exit(self):
        """Called when the application is exiting."""
        self.logger.info("Application is exiting...")
        self.logger.info(f"Exit time: {datetime.now()}")
        
        # Log exit stack trace to see where exit came from
        import traceback
        self.logger.info("Exit called from:")
        for line in traceback.format_stack():
            self.logger.info(line.strip())
        
        # Log any active threads
        active_threads = threading.enumerate()
        self.logger.info(f"Active threads at exit: {len(active_threads)}")
        for thread in active_threads:
            if thread != threading.current_thread():
                self.logger.info(f"  Thread: {thread.name} (alive: {thread.is_alive()})")
        
        # Check continuous batch manager status
        if hasattr(self, 'continuous_batch_manager'):
            self.logger.info(f"Continuous batch manager running: {getattr(self.continuous_batch_manager, 'running', 'N/A')}")
            self.logger.info(f"Continuous batch manager shutdown requested: {getattr(self.continuous_batch_manager, 'shutdown_requested', 'N/A')}")
            
            # Log batch status
            running_batches = getattr(self.continuous_batch_manager, 'running_batches', {})
            self.logger.info(f"Running batches at exit: {len(running_batches)}")
            for batch_id, info in running_batches.items():
                self.logger.info(f"  - {batch_id}: user={getattr(info, 'user', 'unknown')}")
        
        self.logger.info("=== EXIT DEBUG COMPLETE ===")
    
    def _validate_configuration_security(self):
        """Validate configuration for security issues."""
        try:
            warnings = self.config_security.validate_config_security(self.config.config)
            
            if warnings:
                self.logger.warning("Configuration security warnings:")
                for warning in warnings:
                    self.logger.warning(f"  - {warning}")
                    
        except Exception as e:
            self.logger.warning(f"Error during security validation: {e}")
    
    def _initialize_components(self):
        """Initialize all core components with proper error handling."""
        try:
            # Initialize sheet manager and cache
            self.sheet_manager = SheetManager(self.config)
            self.cache_manager = CacheManager(self.config, self.sheet_manager)
            
            # Initialize AI service
            self.ai_service = AIService(self.config, self.cache_manager)
            if self.ai_service.disabled:
                self.logger.warning("AI service is disabled. No API calls will be made.")
            
            # Initialize batch processors
            self.batch_processor = BatchProcessor(
                config=self.config,
                ai_service=self.ai_service,
                sheet_manager=self.sheet_manager,
                cache_manager=self.cache_manager
            )
            
            self.continuous_batch_manager = ContinuousBatchManager(
                config=self.config,
                ai_service=self.ai_service,
                sheet_manager=self.sheet_manager,
                cache_manager=self.cache_manager
            )

            # Initialize unified item processor for complete/once modes
            self.item_processor = ItemProcessor(
                config=self.config,
                ai_service=self.ai_service,
                sheet_manager=self.sheet_manager,
                cache_manager=self.cache_manager,
                logger=self.logger
            )

            # Initialize error notifier
            self.error_notifier = ErrorNotifier(self.config)
            
            # Initialize caches on startup
            self._initialize_caches()
            
        except Exception as e:
            self.logger.error(f"Failed to initialize components: {e}")
            raise
    
    def _initialize_caches(self):
        """Initialize caches with proper error handling."""
        try:
            self.logger.info("Initializing caches...")
            refreshed, content_changed = self.cache_manager.refresh_if_needed()
            
            if refreshed:
                self.logger.info(f"Initialized caches: {', '.join(refreshed)}")
            else:
                self.logger.info("All caches are up to date")
                
        except Exception as e:
            self.logger.warning(f"Error during cache initialization: {e}")
            # Continue anyway - caches will be refreshed on first use
    
    def enable_sound_notifications(self):
        """Enable sound notifications for AI results."""
        self.notification_system.enable()
        self.logger.info("Sound notifications enabled")
        
        # Set up notification callbacks for batch processors
        self.batch_processor.completion_callback = self._on_processing_complete
        self.continuous_batch_manager.completion_callback = self._on_processing_complete
    
    def enable_immediate_mode(self):
        """Enable immediate/synchronous AI processing for predictable timing."""
        self.immediate_mode_enabled = True
        self.logger.info("Immediate mode enabled - AI requests will be processed synchronously")
        self.logger.info("This provides predictable timing but may be slower for large batches")
    
    def _on_processing_complete(self, count: int = 1, context: str = ""):
        """Handle processing completion notifications.
        
        Args:
            count: Number of items processed
            context: Context description
        """
        self.notification_system.notify_completion(count, context, "translation note")
    
    def setup_signal_handlers(self):
        """Setup signal handlers for graceful shutdown."""
        self._shutdown_requested = False
        self._soft_stop_requested = False
        self._shutdown_timeout = 30  # seconds
        self._signal_count = 0
        
        def signal_handler(signum, frame):
            self._signal_count += 1
            
            if self._signal_count == 1:
                # First signal - soft stop (don't send new requests, wait for pending)
                self.logger.info("=== SOFT STOP REQUESTED ===")
                self.logger.info("No new AI requests will be sent. Waiting for pending responses...")
                self._soft_stop_requested = True
                
                # Signal continuous batch manager to stop accepting new work
                if hasattr(self, 'continuous_batch_manager'):
                    self.continuous_batch_manager.request_soft_stop()
                
                print("\nðŸ›‘ SOFT STOP: No new AI requests will be sent.")
                print("ðŸ’¾ Waiting for pending responses to complete...")
                print("ðŸ”´ Press Ctrl+C again for immediate hard stop")
                
            elif self._signal_count == 2:
                # Second signal - graceful shutdown (stop new work, finish current batches)
                self.logger.info("=== GRACEFUL SHUTDOWN REQUESTED ===")
                self.logger.info("Graceful shutdown initiated. Stopping all processing...")
                self._shutdown_requested = True
                self.running = False
                
                # Stop continuous batch manager if running
                if hasattr(self, 'continuous_batch_manager'):
                    self.continuous_batch_manager.stop()
                
                print("\nâš ï¸ GRACEFUL SHUTDOWN: Stopping all processing...")
                print("ðŸ”´ Press Ctrl+C again to force immediate exit")
                
                # Start a timer for forced shutdown
                def force_shutdown():
                    if self._shutdown_requested:
                        self.logger.error(f"Graceful shutdown timeout ({self._shutdown_timeout}s), forcing exit!")
                        sys.exit(1)
                
                timer = threading.Timer(self._shutdown_timeout, force_shutdown)
                timer.daemon = True
                timer.start()
                
            else:
                # Third signal - force immediate exit
                self.logger.warning("FORCE EXIT: Immediate termination requested!")
                print("\nðŸ’¥ FORCE EXIT: Terminating immediately!")
                sys.exit(1)
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
    
    def run_continuous(self):
        """Run in continuous monitoring mode."""
        try:
            self.running = True
            self.logger.info("=== STARTING CONTINUOUS MODE ===")
            
            if self.use_continuous_processing:
                self.logger.info("Starting continuous batch processing mode...")
                print("ðŸš€ Starting continuous batch processing...")
                print("ðŸ“‹ Keyboard controls:")
                print("   ðŸ›‘ Ctrl+C once:  SOFT STOP (no new requests, wait for pending)")
                print("   âš ï¸  Ctrl+C twice: GRACEFUL SHUTDOWN (stop processing)")
                print("   ðŸ’¥ Ctrl+C three: FORCE EXIT (immediate termination)")
                print()
                
                # Log before starting continuous batch manager
                self.logger.info("About to start continuous batch manager...")
                self.continuous_batch_manager.start()
                self.logger.info("Continuous batch manager.start() returned - should not reach here unless shutdown")
                
                # Keep the main thread alive with periodic heartbeat logging
                loop_count = 0
                heartbeat_interval = 300  # Log heartbeat every 5 minutes
                
                while self.running and not getattr(self, '_shutdown_requested', False):
                    try:
                        time.sleep(self.timing_config['loop_sleep_interval'])
                        loop_count += 1
                        
                        # Handle soft stop - check if all batches are complete
                        if self._soft_stop_requested and not self._shutdown_requested:
                            with getattr(self.continuous_batch_manager, 'lock', threading.Lock()):
                                pending_batches = len(getattr(self.continuous_batch_manager, 'running_batches', {}))
                                
                            if pending_batches == 0:
                                self.logger.info("=== SOFT STOP COMPLETE ===")
                                self.logger.info("All pending batches completed. Exiting cleanly.")
                                print("\nâœ… SOFT STOP COMPLETE: All pending responses received. Exiting cleanly.")
                                self.running = False
                                break
                            else:
                                # Log soft stop progress periodically
                                if loop_count % 30 == 0:  # Every 30 loops (roughly every 30 seconds)
                                    self.logger.info(f"Soft stop in progress: {pending_batches} pending batch(es) remaining...")
                                    print(f"ðŸ’¾ Soft stop: {pending_batches} pending batch(es) remaining...")
                        
                        # Log heartbeat periodically and perform health check
                        if loop_count % (heartbeat_interval // self.timing_config['loop_sleep_interval']) == 0:
                            self.logger.info(f"Heartbeat: Application running normally (loop #{loop_count})")
                            self.health_check()
                    
                    except Exception as loop_error:
                        self.logger.error(f"Error in main loop: {loop_error}")
                        self.logger.error("Main loop traceback:")
                        for line in traceback.format_exc().split('\n'):
                            if line.strip():
                                self.logger.error(line)
                        # Continue the loop unless it's a critical error
                        time.sleep(5)
                    
            else:
                self.logger.info("Starting legacy polling mode...")
                self._run_legacy_continuous()
                
        except KeyboardInterrupt:
            self.logger.info("KeyboardInterrupt in run_continuous - initiating shutdown")
        except Exception as e:
            self.logger.error(f"Critical error in continuous mode: {e}")
            self.logger.error("Critical error traceback:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    self.logger.error(line)
            raise
        finally:
            self.logger.info("=== CONTINUOUS MONITORING STOPPED ===")
            try:
                if hasattr(self, 'continuous_batch_manager'):
                    self.continuous_batch_manager.stop()
            except Exception as stop_error:
                self.logger.error(f"Error stopping continuous batch manager: {stop_error}")
    
    def _run_legacy_continuous(self):
        """Run legacy continuous processing with polling."""
        import schedule
        
        # Schedule periodic checks
        poll_interval = self.config.get('processing.poll_interval', 60)
        schedule.every(poll_interval).seconds.do(self.check_for_work)
        
        self.logger.info(f"Starting continuous monitoring (polling every {poll_interval}s)...")
        
        while self.running and not getattr(self, '_shutdown_requested', False):
            try:
                schedule.run_pending()
                time.sleep(self.timing_config['loop_sleep_interval'])
                
            except Exception as e:
                self.logger.error(f"Error in polling cycle: {e}")
                time.sleep(self.timing_config['retry_delay_brief'])  # Brief pause before retrying
    
    def run_once(self, dry_run: bool = False):
        """Run one-time processing."""
        try:
            if dry_run:
                self.logger.info("Running in DRY RUN mode - no changes will be made")
            
            self.check_for_work()
            self.logger.info("One-time processing completed")
            
        except Exception as e:
            self.logger.error(f"Error in one-time processing: {e}")
            raise
    
    def run_complete(self, dry_run: bool = False):
        """Run processing until no work is found - suitable for cron jobs."""
        try:
            if dry_run:
                self.logger.info("Running in DRY RUN mode - no changes will be made")
            
            self.running = True
            cycle_count = 0
            total_processed = 0
            
            self.logger.info("=== STARTING COMPLETE MODE ===")
            self.logger.info("Processing will continue until no work is found across all sheets")
            
            while self.running and not getattr(self, '_shutdown_requested', False):
                cycle_count += 1
                self.logger.info(f"=== Processing cycle {cycle_count} ===")
                
                # Check for work and count items processed
                cycle_processed = self._check_for_work_with_count()
                total_processed += cycle_processed
                
                if cycle_processed == 0:
                    self.logger.info("No work found in this cycle - processing complete")
                    break
                else:
                    self.logger.info(f"Processed {cycle_processed} items in cycle {cycle_count}")
                    
                    # Small delay between cycles to avoid overwhelming the system
                    if self.running and not getattr(self, '_shutdown_requested', False):
                        import time
                        time.sleep(self.timing_config.get('cycle_delay', 2))
            
            self.logger.info(f"=== COMPLETE MODE FINISHED ===")
            self.logger.info(f"Total cycles: {cycle_count}")
            self.logger.info(f"Total items processed: {total_processed}")
            
            if getattr(self, '_shutdown_requested', False):
                self.logger.info("Processing stopped due to shutdown request")
            else:
                self.logger.info("Processing completed - no more work found")
            
        except KeyboardInterrupt:
            self.logger.info("Complete mode interrupted by user")
        except Exception as e:
            self.logger.error(f"Error in complete mode: {e}")
            raise
        finally:
            self.running = False
    
    def _check_for_work_with_count(self) -> int:
        """Check all sheets for new work and process it, returning count of processed items."""
        try:
            if getattr(self, '_shutdown_requested', False):
                self.logger.info("Shutdown requested, skipping work check")
                return 0
            
            self.logger.debug("Checking for new work...")
            
            # Get sheet IDs and ensure caches are ready
            sheet_ids = self.config.get('google_sheets.sheet_ids', {})
            self._ensure_support_references()
            
            # Process each sheet
            total_processed = 0
            auto_convert_sref = self.config.get('processing.auto_convert_sref', True)
            
            for editor_key, sheet_id in sheet_ids.items():
                if getattr(self, '_shutdown_requested', False):
                    break
                
                # Get friendly name for logging
                friendly_name = self.config.get_friendly_name_with_id(editor_key)
                
                # Check if sheet is blocked
                if self._is_sheet_blocked(sheet_id, editor_key):
                    continue
                
                try:
                    # Process suggestions and regular work
                    processed_count = self._process_sheet_work(sheet_id, editor_key, auto_convert_sref)
                    total_processed += processed_count
                    
                except Exception as e:
                    if self._is_permission_error(e):
                        self._block_sheet_for_permission_error(sheet_id, editor_key)
                    else:
                        self.logger.error(f"Error processing {friendly_name}: {e}")
                        self.handle_error(e, f"Processing work for {friendly_name}")
            
            if total_processed > 0:
                self.logger.info(f"Processed {total_processed} items across all sheets")
            else:
                self.logger.debug("No work found")
            
            return total_processed
                
        except Exception as e:
            self.logger.error(f"Error checking for work: {e}")
            self.handle_error(e, "Checking for work")
            return 0
    
    def check_for_work(self):
        """Check all sheets for new work and process it (legacy synchronous mode)."""
        self._check_for_work_with_count()
    
    def _ensure_support_references(self):
        """Ensure support references are cached."""
        support_references = self.cache_manager.get_cached_data('support_references')
        if not support_references:
            self.logger.debug("Support references not cached, fetching...")
            support_references = self.sheet_manager.fetch_support_references()
            if support_references:
                self.cache_manager.set_cached_data('support_references', support_references)
            else:
                self.logger.warning("Failed to fetch support references - SRef conversion may not work properly")
    
    def _process_sheet_work(self, sheet_id: str, editor_key: str, auto_convert_sref: bool) -> int:
        """Process work for a single sheet.

        Args:
            sheet_id: Google Sheets ID
            editor_key: Editor key (raw ID like 'editor3')
            auto_convert_sref: Whether to auto-convert SRef values

        Returns:
            Number of items processed
        """
        # Check for suggestion requests first
        self._check_and_process_suggestion_requests(sheet_id, editor_key)

        # Get friendly name for logging
        editor_name = self.config.get_friendly_name_with_id(editor_key)

        # Convert SRef values if enabled
        if auto_convert_sref:
            self._convert_sref_values_for_sheet(sheet_id, editor_name)

        # Delegate ALL processing to ItemProcessor (handles J1 trigger + pending work)
        processed_count = self.item_processor.check_and_process_sheet(
            sheet_id=sheet_id,
            user=editor_key,
            immediate_mode=self.immediate_mode_enabled
        )

        if processed_count > 0:
            self.logger.info(f"Processed {processed_count} items for {editor_name}")

        return processed_count
    
    def _convert_sref_values_for_sheet(self, sheet_id: str, editor_name: str):
        """Convert SRef values for a specific sheet."""
        try:
            support_references = self.cache_manager.get_cached_data('support_references')
            if not support_references:
                return
            
            all_items = self.sheet_manager.get_all_rows_for_sref_conversion(sheet_id)
            if not all_items:
                return
            
            updates_needed = self.sheet_manager.convert_sref_values(all_items, support_references)
            if updates_needed:
                self.logger.info(f"Converting {len(updates_needed)} SRef values for {editor_name}")
                
                if not self.config.get('debug.dry_run', False):
                    self.sheet_manager.batch_update_rows(sheet_id, updates_needed)
                    self.logger.info(f"Successfully updated {len(updates_needed)} SRef values for {editor_name}")
                else:
                    self.logger.info("DRY RUN: Would update SRef values")
                    
        except Exception as e:
            self.logger.warning(f"Error during SRef conversion for {editor_name}: {e}")
    
    def _is_sheet_blocked(self, sheet_id: str, editor_name: str) -> bool:
        """Check if a sheet is blocked due to permission errors."""
        if sheet_id in self.blocked_sheets:
            blocked_until = self.blocked_sheets[sheet_id]
            if datetime.now() < blocked_until:
                remaining = (blocked_until - datetime.now()).total_seconds() / 60
                self.logger.debug(f"Sheet {editor_name} blocked for {remaining:.1f} more minutes")
                return True
            else:
                # Block expired, remove it
                del self.blocked_sheets[sheet_id]
        
        return False
    
    def _block_sheet_for_permission_error(self, sheet_id: str, editor_name: str):
        """Block a sheet due to permission errors."""
        block_until = datetime.now() + timedelta(hours=self.permission_block_hours)
        self.blocked_sheets[sheet_id] = block_until
        friendly_name_with_id = self.config.get_friendly_name_with_id(editor_name)
        self.logger.warning(f"Blocked {friendly_name_with_id} for {self.permission_block_hours} hour(s) due to permission error")
    
    def _is_permission_error(self, error: Exception) -> bool:
        """Check if an error is a permission-related error."""
        error_str = str(error).lower()
        permission_indicators = [
            'permission denied',
            'insufficient permissions',
            '403',
            'forbidden',
            'access denied'
        ]
        return any(indicator in error_str for indicator in permission_indicators)
    
    def handle_error(self, error: Exception, context: str = ""):
        """Handle errors with proper logging and notification.
        
        Args:
            error: The exception that occurred
            context: Context description for the error
        """
        try:
            self.error_count += 1
            
            # Sanitize error message for logging
            safe_error_msg = self.security_validator.sanitize_log_message(str(error))
            safe_context = self.security_validator.sanitize_log_message(context)
            
            self.logger.error(f"=== ERROR #{self.error_count} ===")
            self.logger.error(f"Context: {safe_context}")
            self.logger.error(f"Error type: {type(error).__name__}")
            self.logger.error(f"Error message: {safe_error_msg}")
            
            # Log full traceback for debugging
            if hasattr(error, '__traceback__') and error.__traceback__:
                self.logger.error("Full traceback:")
                for line in traceback.format_tb(error.__traceback__):
                    self.logger.error(line.rstrip())
            
            # Log current thread information
            current_thread = threading.current_thread()
            self.logger.error(f"Thread: {current_thread.name} (ID: {current_thread.ident})")
            
            # Send error notifications if configured
            if self.config.get('logging.email_errors', False):
                self._send_error_notification(safe_error_msg, safe_context)
            
        except Exception as e:
            self.logger.error(f"Error in error handler: {e}")
            self.logger.error("Error handler traceback:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    self.logger.error(line)
    
    def _send_error_notification(self, error_msg: str, context: str):
        """Send error notification email if appropriate."""
        try:
            # Implement cooldown to avoid spam
            now = datetime.now()
            cooldown_minutes = self.config.get('logging.email_cooldown_minutes', 10)
            
            if (self.last_error_notification and 
                (now - self.last_error_notification).total_seconds() < cooldown_minutes * 60):
                return
            
            self.error_notifier.send_error_notification(
                f"Translation Notes AI Error in {context}",
                error_msg
            )
            
            self.last_error_notification = now
            
        except Exception as e:
            self.logger.error(f"Failed to send error notification: {e}")
    
    # Utility methods for CLI commands
    def force_refresh_templates(self) -> bool:
        """Force refresh template cache."""
        try:
            self.cache_manager.clear_cache('templates')
            templates = self.sheet_manager.fetch_templates()
            if templates:
                self.cache_manager.set_cached_data('templates', templates)
                self.logger.info("Template cache refreshed successfully")
                return True
            else:
                self.logger.error("Failed to refresh template cache")
                return False
        except Exception as e:
            self.logger.error(f"Error refreshing template cache: {e}")
            return False
    
    def force_refresh_support_refs(self) -> bool:
        """Force refresh support references cache."""
        try:
            self.cache_manager.clear_cache('support_references')
            support_refs = self.sheet_manager.fetch_support_references()
            if support_refs:
                self.cache_manager.set_cached_data('support_references', support_refs)
                self.logger.info("Support references cache refreshed successfully")
                return True
            else:
                self.logger.error("Failed to refresh support references cache")
                return False
        except Exception as e:
            self.logger.error(f"Error refreshing support references cache: {e}")
            return False
    
    def get_cache_status(self):
        """Display cache status information."""
        try:
            cache_info = self.cache_manager.get_cache_info()
            
            print("\n=== Cache Status ===")
            for cache_name, info in cache_info.items():
                status = "âœ“ Valid" if info['valid'] else "âœ— Invalid/Missing"
                size_mb = info.get('size_mb', 0)
                last_updated = info.get('last_updated', 'Never')
                
                print(f"{cache_name}: {status}")
                print(f"  Size: {size_mb:.2f} MB")
                print(f"  Last Updated: {last_updated}")
                print()
                
        except Exception as e:
            self.logger.error(f"Error getting cache status: {e}")
    
    def convert_sref_values(self) -> bool:
        """Convert SRef values for all sheets."""
        try:
            sheet_ids = self.config.get('google_sheets.sheet_ids', {})
            total_converted = 0
            
            for editor_key, sheet_id in sheet_ids.items():
                friendly_name = self.config.get_friendly_name_with_id(editor_key)
                self.logger.info(f"Converting SRef values for {friendly_name}...")
                self._convert_sref_values_for_sheet(sheet_id, friendly_name)
                
            return True
            
        except Exception as e:
            self.logger.error(f"Error converting SRef values: {e}")
            return False
    
    def convert_language_roundtrip(self) -> bool:
        """Run roundtrip language conversion (Englishâ†’Hebrew/Greekâ†’English) for all sheets.
        
        This updates the GLQuote, OrigL, and ID columns without running AI processing.
        Useful for refreshing language conversion data independently.
        
        Returns:
            True if successful, False otherwise
        """
        try:
            from modules.language_converter import LanguageConverter
            from modules.processing_utils import update_conversion_data_immediately
            
            sheet_ids = self.config.get('google_sheets.sheet_ids', {})
            total_sheets = len(sheet_ids)
            successful_sheets = 0
            
            self.logger.info(f"Starting roundtrip language conversion for {total_sheets} sheet(s)")
            print(f"\nðŸ”„ Running roundtrip language conversion for {total_sheets} sheet(s)...")
            
            for editor_key, sheet_id in sheet_ids.items():
                friendly_name = self.config.get_friendly_name_with_id(editor_key)
                
                try:
                    self.logger.info(f"Processing {friendly_name}...")
                    print(f"\nðŸ“‹ Processing {friendly_name}...")
                    
                    # Get all items from the sheet (not just pending ones)
                    # We want to update language conversion for all rows
                    all_items = self.sheet_manager.get_all_rows_for_sref_conversion(sheet_id)
                    
                    if not all_items:
                        self.logger.info(f"No items found for {friendly_name}, skipping")
                        print(f"  âš ï¸  No items found, skipping")
                        continue
                    
                    # Detect book from items (gracefully handles blank first rows)
                    user, book = self.cache_manager.detect_user_book_from_items(all_items)
                    
                    if not book:
                        self.logger.warning(f"Could not detect book for {friendly_name}")
                        print(f"  âš ï¸  Could not detect book")
                        print(f"  ðŸ’¡ Make sure your spreadsheet has a 'Book' column with values like: GEN, EXO, MAT, MRK, etc.")
                        if all_items:
                            available_columns = list(all_items[0].keys())
                            if 'Book' not in available_columns:
                                print(f"  âŒ No 'Book' column found in spreadsheet")
                                print(f"  ðŸ“Š Available columns: {', '.join(available_columns)}")
                            else:
                                print(f"  ðŸ“‹ 'Book' column exists but all rows appear to be empty")
                        continue
                    
                    self.logger.info(f"Detected book: {book}, converting {len(all_items)} item(s)")
                    print(f"  ðŸ“– Book: {book}")
                    print(f"  ðŸ“ Items: {len(all_items)}")
                    
                    # Run language conversion
                    converter = LanguageConverter(cache_manager=self.cache_manager)
                    enriched_items = converter.enrich_items_with_conversion(
                        items=all_items,
                        book_code=book,
                        sheet_manager=self.sheet_manager,
                        sheet_id=sheet_id,
                        verbose=True
                    )
                    
                    # Update sheet with conversion data
                    if not self.config.get('debug.dry_run', False):
                        update_conversion_data_immediately(
                            items=enriched_items,
                            sheet_id=sheet_id,
                            sheet_manager=self.sheet_manager,
                            config=self.config,
                            logger=self.logger
                        )
                        self.logger.info(f"Successfully updated language conversion for {friendly_name}")
                        print(f"  âœ… Successfully updated {len(enriched_items)} item(s)")
                        successful_sheets += 1
                    else:
                        self.logger.info(f"DRY RUN: Would update {len(enriched_items)} items for {friendly_name}")
                        print(f"  ðŸ” DRY RUN: Would update {len(enriched_items)} item(s)")
                        successful_sheets += 1
                    
                except Exception as e:
                    self.logger.error(f"Error converting language for {friendly_name}: {e}", exc_info=True)
                    print(f"  âŒ Error: {e}")
                    continue
            
            # Summary
            self.logger.info(f"Language conversion complete: {successful_sheets}/{total_sheets} sheet(s) successful")
            print(f"\nâœ¨ Language conversion complete!")
            print(f"   Successfully processed: {successful_sheets}/{total_sheets} sheet(s)")
            
            return successful_sheets > 0
            
        except Exception as e:
            self.logger.error(f"Error in language conversion: {e}", exc_info=True)
            print(f"\nâŒ Error during language conversion: {e}")
            return False
    
    def health_check(self):
        """Perform a comprehensive health check and log status."""
        try:
            self.logger.info("=== HEALTH CHECK ===")
            self.logger.info(f"Application running: {self.running}")
            self.logger.info(f"Error count: {self.error_count}")
            
            # Check thread status
            active_threads = threading.enumerate()
            self.logger.info(f"Active threads: {len(active_threads)}")
            for thread in active_threads:
                self.logger.info(f"  - {thread.name}: alive={thread.is_alive()}, daemon={thread.daemon}")
            
            # Check continuous batch manager status
            if hasattr(self, 'continuous_batch_manager'):
                self.logger.info(f"Continuous batch manager running: {getattr(self.continuous_batch_manager, 'running', 'N/A')}")
                self.logger.info(f"Continuous batch manager shutdown requested: {getattr(self.continuous_batch_manager, 'shutdown_requested', 'N/A')}")
            
            # Check cache status
            try:
                cache_info = self.cache_manager.get_cache_info()
                self.logger.info(f"Cache status: {len(cache_info)} caches")
                for cache_name, info in cache_info.items():
                    self.logger.info(f"  - {cache_name}: valid={info.get('valid', False)}")
            except Exception as cache_error:
                self.logger.warning(f"Could not check cache status: {cache_error}")
            
            self.logger.info("=== END HEALTH CHECK ===")
            
        except Exception as e:
            self.logger.error(f"Error during health check: {e}")
    
    def _check_and_process_suggestion_requests(self, sheet_id: str, editor_key: str):
        """Check for suggestion requests and process them if conditions are met.
        
        Args:
            sheet_id: Google Sheets ID
            editor_key: Editor key (raw ID like 'editor3')
        """
        try:
            # Check if suggestion request exists
            if not self._has_suggestion_request(sheet_id):
                return
            
            # Get friendly name for logging
            friendly_name_with_id = self.config.get_friendly_name_with_id(editor_key)
            self.logger.info(f"Found suggestion request for {friendly_name_with_id}")
            
            # Check if other work is in progress
            if self._is_other_work_in_progress(sheet_id):
                self.logger.info(f"Other work in progress for {friendly_name_with_id}, skipping suggestions")
                return
            
            # Process the suggestion request using continuous batch manager
            if hasattr(self, 'continuous_batch_manager'):
                self.continuous_batch_manager._process_suggestion_request(sheet_id, editor_key)
            else:
                self.logger.warning(f"Continuous batch manager not available for suggestions processing for {friendly_name_with_id}")
            
        except Exception as e:
            friendly_name_with_id = self.config.get_friendly_name_with_id(editor_key)
            self.logger.error(f"Error checking suggestion requests for {friendly_name_with_id}: {e}")

    def _has_suggestion_request(self, sheet_id: str) -> bool:
        """Check if there's a suggestion request (YES in suggested notes tab, column D, row 2).
        
        Args:
            sheet_id: Google Sheets ID
            
        Returns:
            True if suggestion request exists
        """
        try:
            # Read from suggested notes tab, column D, row 2
            range_name = "'suggested notes'!D2"
            
            result = self.sheet_manager.service.spreadsheets().values().get(
                spreadsheetId=sheet_id,
                range=range_name
            ).execute()
            
            values = result.get('values', [])
            
            if values and len(values) > 0 and len(values[0]) > 0:
                value = values[0][0].strip().upper()
                return value == 'YES'
            
            return False
            
        except Exception as e:
            self.logger.debug(f"Error checking suggestion request: {e}")
            return False

    def _is_other_work_in_progress(self, sheet_id: str) -> bool:
        """Check if other work is in progress (Go? column has non-AI values).
        
        Args:
            sheet_id: Google Sheets ID
            
        Returns:
            True if other work is in progress
        """
        try:
            # Read from AI notes tab, column F (Go?)
            range_name = "'AI notes'!F:F"
            
            result = self.sheet_manager.service.spreadsheets().values().get(
                spreadsheetId=sheet_id,
                range=range_name
            ).execute()
            
            values = result.get('values', [])
            
            # Skip header row (index 0) and check all other rows
            for i, row in enumerate(values[1:], start=2):
                if row and len(row) > 0:
                    go_value = row[0].strip()
                    if go_value and go_value.upper() != 'AI':
                        self.logger.debug(f"Found non-AI work in progress: row {i}, Go? = '{go_value}'")
                        return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"Error checking work in progress: {e}")
            return True  # Assume work in progress on error


def main():
    """Main entry point using our new CLI system with enhanced error handling."""
    try:
        return main_cli_entry_point(TranslationNotesAI)
    except KeyboardInterrupt:
        print("\nApplication interrupted by user")
        return 0
    except SystemExit as e:
        print(f"\nApplication exited with code: {e.code}")
        return e.code
    except Exception as e:
        print(f"\nCritical error in main: {e}")
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main()) 